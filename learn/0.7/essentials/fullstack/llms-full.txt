<SYSTEM>This is the developer documentation for Dioxus at /learn/0.7/essentials/fullstack/project_setup and all its subroutes.</SYSTEM>

# Project Setup

Fullstack Dioxus apps are structured a bit differently than client-only apps. This distinction has implications on how we organize our apps, requiring more care when adding dependencies and including code.

In this chapter, we'll explore how to use feature flags and cargo targets to structure our apps for fullstack development.

 > 
 > Dioxus provides a number of templates with `dx new` to automatically bootstrap new fullstack projects.
 > 
 > If you want to get started quickly, we suggest using one of the built-in templates and then heading on to next chapter.

## The Server/Client split

A "fullstack" application is actually composed of at least two distinct binaries:

* The client binary that runs the web, desktop, or mobile application
* The server binary that renders the initial HTML and runs server functions

Because our client app and server app target different platforms, we need to include different code and different dependencies. You can conceptualize the "server" as just another platform for your app, just like you might target both iOS and Android. The server will have different dependencies than the client app, and thus you need to properly configure your app's `Cargo.toml` and build flags.

## How DX builds your app

Our build tool, DX, is capable of building both the client and server of your app simultaneously. If the `--hotpatch` flag is enabled, DX will also automatically hot-reload both the client and server code in tandem.

When developing your app, you'll generally use `dx serve`. This command accepts the usual arguments you might pass to `cargo run`:

````sh
# We can customize the build's features, profile, or release mode
dx serve --features "spicy" --release

# We can specify examples, packages, and binaries
dx serve --example dogs
````

Under the hood, DX automatically detects if the target app has a server variant by checking its `Cargo.toml` for a Cargo feature called "server". In this Cargo feature, you would enable the `server` feature on Dioxus:

````toml
[features]
server = ["dioxus/server"]
````

DX will also look for specific client features (`"web"` / `"desktop"` / `"mobile"`) and enable the relevant feature depending on the target platform. DX uses the concept of "platform" to distinguish types of builds from one another.

To set a build's platform, you can use `--web`, `--desktop`, `--ios`, etc. When you specify a platform, DX also enables a corresponding feature in your Cargo.toml:

````toml
# enabled with `--web`
web = ["dioxus/web"]

# enabled with `--desktop`
desktop = ["dioxus/desktop"]

# enabled with `--mobile`
mobile = ["dioxus/mobile"]
````

Running the command might look like:

````sh
# sets target=wasm32-unknown-unknown, features="web", profile="wasm-dev"
dx serve --web

# sets target=host, features="desktop", profile="desktop-dev"
dx serve --desktop

# sets target=aarch64-apple-ios-sim, features="mobile", profile="ios-dev"
dx serve --ios
````

If your `dioxus` dependency enables the `fullstack` feature, DX recognizes this app is a fullstack app and then creates two builds, each with a separate platform:

````toml
[dependencies]
dioxus = { version = "0.7", features = ["fullstack"] }

[features]
web = ["dioxus/web"]
server = ["dioxus/server"]
````

Internally, DX splits your input command into two separate `cargo build` commands, each with a different platform.

![Server Client Split](/assets/06_docs/server_split.png)

Feature flags like these for the client and server are automatically generated by the CLI when you run `dx new` with fullstack enabled. If you are creating a project from scratch, you will need to add the feature flags manually.

 > 
 > If you are not familiar with features in rust, you can read more about feature flags in the [cargo reference](https://doc.rust-lang.org/cargo/reference/features.html).

## Customizing the Builds

A fullstack app is comprised of two separate binaries, so DX provides a way to customize each. Usually, the default `dx serve` command is sufficient, but for complex app setups that need per-target customization, you can use the `@client` and `@server` modifiers to pass target-specific cargo args to each:

````sh
dx serve \
  @client --ios --features "optimizations" \
  @server --bin server
````

This syntax makes it possible to have two separate entrypoints for our app. This can be extremely useful if you have an existing backend and would like to launch that alongside your Dioxus frontend.

By default, DX isolates your server and client builds by levaraging Cargo Profiles. Cargo profiles let us specify certain build modifiers like opt-level, debug symbols, LTO, and other optimizations.

DX will use these profiles

* `web-dev` / `web-release`: targeting the web with `--web`
* `server-dev` / `server-release`: targeting the server (implicitly, or with `--server`)
* `desktop-dev` / `desktop-release`: targeting desktop apps with `--desktop`
* `ios-dev` / `ios-release`: targeting iOS apps with `--ios`
* `android-dev` / `android-release`: targeting Android apps with `--android`

These profiles correspond 1:1 with the "platforms" DX supports. Note that a `platform` is just a way of DX to isolate two builds from each other. You can completely customize the build, including:

* `--renderer`: swap between the various 1st-party renderers (ie `--renderer native`)
* `--bundle`: the bundle format of the build (`.app`, `.apk`, `.ipa`, etc.)
* all cargo options (`--features`, `--target`, `--profile`, `--bin`, etc.)

## Adding Server Only Dependencies

Many dependencies like [`tokio`](https://docs.rs/tokio/latest/tokio/index.html) cannot be compiled to WebAssembly, and thus should only be built for the server. If these dependencies are enabled when building a WASM bundle, you will receive cryptic compilation errors. As such, we need to take care not to accidentally add server-only dependencies to our client app.

For example, if we want to interact with the filesystem in a server function, we might want to add `tokio`. The `tokio` crate provides utilities for working with async IO with abstractions like [`tokio::fs::File`](https://docs.rs/tokio/latest/tokio/fs/struct.File.html). Unfortunately, if try to add `tokio` with its `full` feature set, we will receive a compilation error:

````toml
[dependencies]
# ...
# ❌ If tokio is added as a required dependency, it will be included in both the server
# and the web bundle. The web bundle will fail to build because tokio is not
# compatible with wasm
tokio = { version = "1", features = ["full"] }
````

````sh
error[E0432]: unresolved import `crate::sys::IoSourceState`
  --> /Users/user/.cargo/registry/src/index.crates.io-6f17d22bba15001f/mio-1.0.2/src   |source.rs:14:5
14 | use crate::sys::IoSourceState;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ no `IoSourceState` in `sys`
...
````

Since we added `tokio` as a dependency for both the server and the client binary, cargo tries to compile it for each target. This fails because `tokio` is not compatible with the `wasm32-unknown-unknown` target.

To fix the issue, we can **make the dependency optional and only enable it in the server feature**:

````toml
[dependencies]
# ...
# ✅ Since the tokio dependency is optional, it is not included in client bundle.
tokio = { version = "1", features = ["full"], optional = true }

[features]
# ...
# ✅ Since the tokio dependency is enabled in the server feature, it is included in
# the server binary.
server = ["dioxus/server", "dep:tokio"]
````

Now when we build with `dx serve`, the project compiles successfully!

## Adding Client Only Dependencies

Many dependencies like [`wasm-bindgen`](https://docs.rs/wasm-bindgen/latest/wasm_bindgen/index.html) and [`web-sys`](https://docs.rs/web-sys/latest/web_sys/index.html) are only compatible with the client. Unlike server-only dependencies, these dependencies can compile on native targets, but they will panic when used outside of the browser.

You can reduce build times for your server and native binaries by including web dependencies only in the browser client binary.

Instead of adding web only dependencies to every binary in your project like this:

````toml
[dependencies]
# ...
# ❌ If web-sys is added as a required dependency, it will be included in the server,
# native, and the web bundle which makes build times longer.
web-sys = { version = "0.3.60", features = ["console"] }
````

You can make the dependency optional and only enable it in the `web` feature in your `Cargo.toml`:

````toml
[dependencies]
# ...
# ✅ Since the web-sys dependency is optional, it is not included in the server and
# native bundles.
web-sys = { version = "0.3.60", features = ["console"], optional = true }

[features]
# ...
# ✅ Since the web-sys dependency is enabled in the web feature, it is included in
# the web bundle.
web = ["dioxus/web", "dep:web-sys"]
````

## Managing Binary Specific Imports

Once you have set up binary specific dependencies, you need to adjust any of your imports to only import the dependencies when building for the binary that includes those dependencies.

For example, if `tokio` is only enabled in the server feature, you will need to import it like this:

````rs@server_tokio_import.rs
// Since the tokio dependency is only enabled in the server feature,
// we need to only import it when the server feature is enabled.
#[cfg(feature = "server")]
use {tokio::fs::File, tokio::io::AsyncReadExt};
````

You also need to only compile any usage of the dependency when the feature is enabled:

````rs@server_tokio_import.rs
// Since the tokio dependency is only enabled in the server feature,
// we need to only compile any usage of the dependency when the server feature is enabled.
#[cfg(feature = "server")]
async fn read_file() -> Result<String, std::io::Error> {
    let mut file = File::open("path/to/file").await?;
    let mut contents = String::new();
    file.read_to_string(&mut contents).await?;
    Ok(contents)
}

// The bodies of server functions automatically only compile when the server feature is enabled.
#[server]
async fn get_file_contents() -> Result<String> {
    let mut file = File::open("path/to/file").await?;
    let mut contents = String::new();
    file.read_to_string(&mut contents).await?;
    Ok(contents)
}
````

It may be more convenient to group server or client specific code into a module that is only compiled when the feature is enabled:

````rs@server_tokio_import.rs
// Instead of configuring each item that is only used in the server, you can group
// them into a module that is only compiled when the server feature is enabled.
#[cfg(feature = "server")]
mod tokio_utilities {
    use std::path::PathBuf;
    use tokio::fs::File;
    use tokio::io::AsyncReadExt;

    pub async fn read_file(path: PathBuf) -> Result<String, std::io::Error> {
        let mut file = File::open(path).await?;
        let mut contents = String::new();
        file.read_to_string(&mut contents).await?;
        Ok(contents)
    }
}

// Then you can define your server functions using shared utilities you defined for
// server only code.
#[server]
async fn get_file_contents() -> Result<String> {
    let file = tokio_utilities::read_file(PathBuf::from("path/to/file")).await?;
    Ok(file)
}

#[server]
async fn get_other_file_contents() -> Result<String> {
    let file = tokio_utilities::read_file(PathBuf::from("path/to/other/file")).await?;
    Ok(file)
}
````

 > 
 > The [rust reference](https://doc.rust-lang.org/reference/conditional-compilation.html) has more information about conditional compilation in rust.

## Separate Frontend and Backend Crates

If you so choose, you can split your frontend and backend into separate crates. This can be useful for larger projects where you have separate complex entrypoints for web, desktop, and mobile.

Workspace setups bring extra complexity, but they can make it much easier to share data types and functions across several different projects. For instance, you might have a single API crate used by several different apps.

In these cases, we might organize our workspace like so:

````
├── Cargo.toml
└── packages/
    ├── cat-app/
    │     ...
    ├── dog-app/
    │     ...
    └── pet-api/
          ...
````

If you're using Dioxus Fullstack, you can import your `pet-api`'s server functions to call from your UI. In the client app, you can then import the `pet-api` crate:

````toml
[dependencies]
pet-api = { workspace = true }
````

To launch the server, you can choose one of two options:

1. Start the pet-api server from the client project
1. Launch the pet-api crate's main binary

If your server is simple enough, then option 1 can be a decent option since it automatically integrates with `dx serve`.

However, if you choose to have a dedicated server binary, then you'll need to use the `@client` and `@server` modifiers to use a different binary:

````sh
dx serve @client --bin dog-app @server --bin pet-api
````

The built-in "Workspace" Dioxus Template can serve as a good starting point for workspace setups.
# Server Side Rendering

Dioxus Fullstack supports a powerful feature called "server side rendering" (SSR). SSR enables your apps to load data on the server *before* sending HTML to the client.

Server-side-rendering improve's your site's page load times and makes it easier for web crawlers like Google to index. Sites that are easier to index rank higher in web searches, improving your conversion rate and ultimately, your bottom line.

## SSR vs CSR

You might be intimidated by the various terms, tradeoffs, and details. Don't worry - these additional concepts are simply optimizations to make your site perform better in various ways. You can still build a beautiful, useful, accessible site without enhancements like server-side-rendering.

The terms SSR and CSR refer to two different approaches to rendering pages:

* **CSR**: *Client-side-rendering*, data is loaded by a "skeleton" page with `fetch()`
* **SSR**: *Server-side-rendering*, data is loaded on the server and serialized into HTML

SSR gives us the ability to send a more "complete" HTML document to the user when the visit the site, making the site immediately usable and improving its ranking in search results.

### CSR: The "App" Architecture

The architecture of web applications have shifted substantially over the years. Client-side-rendering is a somewhat "modern" architecture where the server responds to user requests with a "skeleton" HTML.

The skeleton HTML might be barebones - something like:

````html

<html>
    <head>
        <meta content="text/html;charset=utf-8" http-equiv="Content-Type" />
        <script src="/index.js"> </script>
    </head>
    <body>
        <div id="main"></div>
    </body>
</html>
````

Note how there's no content *in the HTML document* when it loads. Once this barebones page is loaded by the browser, the `index.js` script executes, calling your app's `main` function. Data fetching is usually done as an *effect* after the initial `main` executes.

When using the CSR approach, there are *many* HTTP requests required to load the page:

* The initial GET to `index.html`
* The GET to `index.js`
* Multiple `GET` calls to backend endpoints to load data

Also note the numerous phases where the app *appears* to be in a loading state:

* The initial HTML is blank
* Once `main` executes, the page is blank, waiting for data to load
* Cascading fetches cause child components to be blank in a "waterfall"

This architecture is called client-side-rendering because the **client** is responsible for rendering the HTML on the page. This approach is well suited for interactive apps with little static content, like document editors, search tools, or anything that is well suited as an "app". This architecture is the primary architecture for desktop and mobile apps.

![CSR Diagram](/assets/07/csr-diagram.avif)

### SSR: The "Site" Architecture

In contrast to CSR, server-side-rendering is widely used for the classic "site" type application. Websites like e-commerce, portfolios, blogs, news, and other content-heavy applications prefer to render the initial HTML **on the server**.

Once the initial HTML reaches the client, extra supporting JavaScript (or WebAssembly) is executed, transforming the static page into an interactive one.

The HTML that reaches the client is usually "complete" with content:

````html
<html>
    <head>
        <meta content="text/html;charset=utf-8" http-equiv="Content-Type" />
        <title> Our Site | Page XYZ </title>
        <meta name="description" content="Our really cool site - Page XYZ" />
        <link href="/main.css" />
        <link href="/page-xyz.css" />
        <script src="/index.js"/>
    </head>
    <body>
        <div id="main">
            <h1> This is a really cool site </h1>
            <h3> You are on page XYZ </h3>
            <p> Enjoy the content! </p>
        </div>
    </body>
</html>
````

Look closely to compare the two HTML bodies. The SSR HTML is full of content - the "main" div has headers and paragraphs, and the "head" of the app has page-specific attributes like its title, meta tags, and page-specific styling.

When using the SSR approach, there are *few* HTTP requests required to load the page:

* Initial GET to load `index.html`
* Follow-up GET requests to load assets

Also note the page only seems to be loading *once*:

* The user is waiting for the `index.html` to download.

Because the initial `GET` requests returns a complete picture of the site, crawlers like Google can easily read your site's contents, improving your ranking in search results.

![SSR Diagram](/assets/07/ssr-diagram.avif)

### Mixing CSR and SSR

Fortunately, these two architectures can be used *together* in a hybrid approach. This comes in two flavors:

* Default to SSR, add reactivity with "islands"
* Default to CSR, caching *some* data from the server

Dioxus employs the second approach. As a framework, we are focused on enabling great "app-like" experiences. Rust excels when building complex logic that is typically found in interaction-heavy applications.

There are *many* frameworks in the first category - projects like Ruby on Rails, NextJS, and Elixir Phoenix all serve primarily server-rendered content quite well. Dioxus easily handles SSR, but provides many tools and utilities that focus on client interaction.

## Do You Need SSR?

SSR is ideal for sites and pages that need to rank well in web searches like e-commerce stores, blogs, news, and other static content. In some instances, if your site is *entirely* static, you can even use static-site-generation to pre-render every page and deploy directly to a CDN.

However, adding SSR to your site is not always necessary, nor does it need to be enabled for every page. Dioxus SSR is *progressive*, meaning that by default, pages are rendered on the client, and you can *opt-in* to rendering components on the server. Any data not cached by the server will become a client-side fetch when the page finally loads.

## Hydration

In dioxus fullstack, the server renders the initial HTML for improved loading times. This initial version of the page is what most web crawlers and search engines see.

After the initial HTML is rendered, the client makes the page interactive through a process called **hydration**. Usually, hydration is purely an enhancement. You generally shouldn't need to think about hydration, but there are a few things you need to keep in mind to avoid [hydration errors](#hydration-errors).

To better understand hydration, let's walk through a simple example:

````rs@hydration.rs
fn Weather() -> Element {
    let mut weather = use_server_future(fetch_weather)?;

    rsx! {
        div {
            "{weather:?}"
        }
        button {
            onclick: move |_| weather.restart(),
            "Refetch"
        }
    }
}
````

## Rendering the initial HTML

When the server receives a request to render the `Weather` component, it renders the page to HTML and serializes some additional data the client needs to hydrate the page. It will follow these steps to render our component:

1. Run the component
1. Wait until all server futures are resolved
1. Serialize any non-deterministic data (like the `weather` future) for the client
1. Render the HTML

[![](https://mermaid.ink/img/pako:eNpdkDFTwzAMhf-KT3M70HbKwELhGMqSdAIziFhNfI2lnGzDQa__HZfk4Iq1-D1_ejr5BK04ggoOg3y0PWoy-61lE_Nbpzj2Jt68WGhI30lN4x2ZmtiReu4svBZwPs4rtckLm13958ZVaa4zmzsJozBxumqK6ynb4-C_yMxTHnLKSvGa3FyCfiabx_3Tbn4sxsTElVkub0vgLNeT3FieChYQSAN6V1Y9XSALqadAFqpydahHC5bPhcOcpPnkFqqkmRagkrseqgMOsag8Oky09Vh-J_y6I_KzSPhH3TufRGfz_A3Ce3PT?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNpdkDFTwzAMhf-KT3M70HbKwELhGMqSdAIziFhNfI2lnGzDQa__HZfk4Iq1-D1_ejr5BK04ggoOg3y0PWoy-61lE_Nbpzj2Jt68WGhI30lN4x2ZmtiReu4svBZwPs4rtckLm13958ZVaa4zmzsJozBxumqK6ynb4-C_yMxTHnLKSvGa3FyCfiabx_3Tbn4sxsTElVkub0vgLNeT3FieChYQSAN6V1Y9XSALqadAFqpydahHC5bPhcOcpPnkFqqkmRagkrseqgMOsag8Oky09Vh-J_y6I_KzSPhH3TufRGfz_A3Ce3PT)

Once the server finishes rendering, it will send this structure to the client as HTML:

[![](https://mermaid.ink/img/pako:eNqFUcFKAzEQ_ZUwh57agy22sAUFqaCgF1sQNCLTZLYbupss2VmLlv67s92luoo4uSRv3nvzhuzBBEuQQJqHnckwslottFdVvd5ELDNVjZ81LCk6zN0HWbVARg0vQpGyLpJhF7xaXbVIU_5MJCmxyV53hJxR7ATkbc96Irxb71i81c3q_u4_3ybKIOe5dW-DDc9P9GPzXJr7bl5yeeg3p51yXTOLa_Amd2b722QmvAdKI1XZH5mb3R57W7VVjb_dJ1_KY241Gl1IQjWQJB02bbGZ9u2BIRQUC3RWPmPfkDTIkII0JHK1GLcatD8ID2sOy3dvIOFY0xBiqDcZJCnmlbzq0iLTwqEELk5oif4phOIH69o6DrEDD5_uGqQ1?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNqFUcFKAzEQ_ZUwh57agy22sAUFqaCgF1sQNCLTZLYbupss2VmLlv67s92luoo4uSRv3nvzhuzBBEuQQJqHnckwslottFdVvd5ELDNVjZ81LCk6zN0HWbVARg0vQpGyLpJhF7xaXbVIU_5MJCmxyV53hJxR7ATkbc96Irxb71i81c3q_u4_3ybKIOe5dW-DDc9P9GPzXJr7bl5yeeg3p51yXTOLa_Amd2b722QmvAdKI1XZH5mb3R57W7VVjb_dJ1_KY241Gl1IQjWQJB02bbGZ9u2BIRQUC3RWPmPfkDTIkII0JHK1GLcatD8ID2sOy3dvIOFY0xBiqDcZJCnmlbzq0iLTwqEELk5oif4phOIH69o6DrEDD5_uGqQ1)

## Hydrating on the client

When the client receives the initial HTML, it hydrates the HTML by rerunning each component. As each component re-reruns, Dioxus loads cached data from the server, properly linking the HTML to each interactive DOM node.

Rerunning each component lets the client re-construct some non-serializable state like event handlers and kick off any client side logic like `use_effect` and `use_future`.

Hydration follows these steps:

1. Deserialize any data from the server (like the `weather` future)
1. Run the component with the deserialized data.
1. Hydrate the HTML sent from the server, adding event listeners and running effects.

[![](https://mermaid.ink/img/pako:eNpdkLFuAjEMhl_F8gxDgemGLlyrDnThmNp0SC-Gi7g4JydpRRHvXsOdkFpnif__s534jG10hBXu-_jddlYy7GrDkMrnQezQQXp4N7juPXGGxjuCl5MT63Nkgx8Kajgv1GYfGTbbUblGWmphTYnE297_EDQkXyTwXHIRSvfqG7tQdlsY1jEMkXXWX3ul9m1u1vm7183kErsRSkuYzx-1zZQuxnRleDw4w0ASrHf60_MVMpg7CmSw0quzcjRo-KKcLTk2J26xylJohhLLocNqb_ukWRmcvqH2VpcT7upg-S3G8I96crolmcTLL4RBdIg?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNpdkLFuAjEMhl_F8gxDgemGLlyrDnThmNp0SC-Gi7g4JydpRRHvXsOdkFpnif__s534jG10hBXu-_jddlYy7GrDkMrnQezQQXp4N7juPXGGxjuCl5MT63Nkgx8Kajgv1GYfGTbbUblGWmphTYnE297_EDQkXyTwXHIRSvfqG7tQdlsY1jEMkXXWX3ul9m1u1vm7183kErsRSkuYzx-1zZQuxnRleDw4w0ASrHf60_MVMpg7CmSw0quzcjRo-KKcLTk2J26xylJohhLLocNqb_ukWRmcvqH2VpcT7upg-S3G8I96crolmcTLL4RBdIg)

## Hydration Errors

For hydration to work, **the component must render exactly the same thing on the client and the server**. If it doesn't, you might see an error like this:

````
Uncaught TypeError: Cannot set properties of undefined (setting 'textContent')
at RawInterpreter.run (yourwasm-hash.js:1:12246)
````

Or this:

````
Error deserializing data:
Semantic(None, "invalid type: floating point `1.2`, expected integer")
This type was serialized on the server at src/main.rs:11:5 with the type name f64. The client failed to deserialize the type i32 at /path/to/server_future.rs
````

### Non-deterministic Data

Much of the logic in your components is "deterministic" - meaning that given the same inputs to a component, the component will render the same output. It's very important that the inputs to your component remain stable across the client and the server.

Some inputs are "non-deterministic". For example, an app like Instagram has a "feed" of content. Calling `GET /api/feed` might not return the same result every time. This type of data must be serialized *into the HTML* and then *deserialized on the client* to ensure the exact same data is used during hydration.

### Non-deterministic Data with Server Cached

You must put any non-deterministic data in `use_server_future`, `use_server_cached` or `use_effect` to avoid hydration errors. For example, if you need to render a random number on your page, you can use `use_server_cached` to cache the random number on the server and then use it on the client:

````rs@hydration.rs
// ❌ The random number will be different on the client and the server
let random: u8 = use_hook(|| rand::random());
// ✅ The same random number will be serialized on the server and deserialized on the client
let random: u8 = use_server_cached(|| rand::random());
````

### Async Loading with Server Futures

If you need render some data from a server future, you need to use `use_server_future` to serialize the data instead of waiting for the (non-deterministic) amount of time `use_resource(...).suspend()?` takes:

````rs@hydration.rs
// ❌ The server function result may be finished on the server, but pending on the client
let random: u8 = use_resource(|| random_server_function()).suspend()?().unwrap_or_default();
// ✅ Once the server function is resolved on the server, it will be sent to the client
let random: u8 = use_server_future(|| random_server_function())?()
    .unwrap()
    .unwrap_or_default();
````

### Async Loading with `use_loader`

New in Dioxus 0.7 is the `use_loader` hook - a hook dedicated for isomorphic data loading that excels in both CSR and SSR architectures.

The `use_loader` hook is very similar to `use_server_future`, but with a slightly different API. Unlike `use_server_future`, the `use_loader` hook will not re-suspend the page when the underlying future re-runs. Also, unlike `use_server_future`, the `use_loader` hook will re-throw any loading errors to the nearest suspense boundary:

````rust
fn app() -> Element {
    // Fetch the list of breeds from the Dog API, using the `?` syntax to suspend or throw errors
    let breed_list = use_loader(move || async move {
        reqwest::get("https://dog.ceo/api/breeds/list/all")
            .await?
            .json::<ListBreeds>()
            .await
    })?;

    rsx! {
        for cur_breed in breed_list.read().message.keys().take(20).cloned() {
            button {
                onclick: move |_| {
                    breed.call(cur_breed.clone());
                },
                "{cur_breed}"
            }
        }
    }
}
````

The `use_loader` hook takes a callback that returns a `Result<T, E>`. If that future returns a result, the error is automatically thrown. The `use_loader` hook excels when building sites that are both highly interactive and require SSR capabilities.

### Client Only Data with Effects

If you need to grab some data that is only available on the client, make sure you get it inside of a `use_effect` hook which runs after the component has been hydrated:

````rs@hydration.rs
// ❌ Using a different value client side before hydration will cause hydration issues
// because the server rendered the html with another value
let mut storage = use_signal(|| {
    #[cfg(feature = "server")]
    return None;
    let window = web_sys::window().unwrap();
    let local_storage = window.local_storage().unwrap().unwrap();
    local_storage.set_item("count", "1").unwrap();
    local_storage.get_item("count").unwrap()
});

// ✅ Changing the value inside of an effect is fine because effects run after hydration
let mut storage = use_signal(|| None);
use_effect(move || {
    let window = web_sys::window().unwrap();
    let local_storage = window.local_storage().unwrap().unwrap();
    local_storage.set_item("count", "1").unwrap();
    storage.set(local_storage.get_item("count").unwrap());
});
````

### Avoid Side Effects in Server Cached Hooks

The dioxus fullstack specific hooks `use_server_cached` and `use_server_future` don't run the same on the server and the client. The server will always run the closure, but the client may not run the closure if the server serialized the result. Because of this, the code you run inside these hooks **cannot have side effects**. If it does, the side effects will not be serialized and it can cause a hydration mismatch error:

````rs@hydration.rs
// ❌ The state of the signal cannot be serialized on the server
let mut storage = use_signal(|| None);
use_server_future(move || async move {
    storage.set(Some(server_future().await));
})?;

// ✅ The value returned from use_server_future will be serialized on the server and hydrated on the client
let storage = use_server_future(|| async move { server_future().await })?;
````
# Server Functions

Dioxus Fullstack provides an ergonomic solution for quickly building your backend API and calling those endpoints on the client called *Server Functions*. Server Functions are regular Rust functions that define an Axum-compatible endpoint:

````rust
#[get("/api/hello-world")]
async fn hello_world() -> Result<String> {
	Ok("Hello world!".to_string())
}
````

Server functions automatically generate an HTTP endpoint for your app. After launching your app, you can `curl` your endpoint directly:

````sh
# returns "Hello world!"
curl http://127.0.0.1:8080/api/hello-world
````

Server functions can be called directly from the client as a function:

````rust
let onclick = move |_| async move {
	let msg = hello_world().await;
	// ...
}
````

Server functions can take all sorts of modifiers like server-only extractors and custom axum payloads, making them even more powerful than a plain axum handler:

````rust
#[get("/api/users/{user_id}", db: SqlDb)]
async fn get_user(user_id: Uuid) -> Result<UserData> {
    db.get(user_id)
}
````

Ultimately, a server function is just an axum endpoint - you can cleanly use the entirety of the Axum ecosystem with server functions!

## Anatomy of a Server Function

A server function is an HTTP endpoint in the form of a Rust function. We can transform a regular function into a server function by annotating it with one of a few procedural macros:

* Explicitly using the `#[get]`, `#[post]`, `#[put]`, `#[delete]`, `#[patch]` macros
* Anonymously with the `#[server]` macro

To make a server function, simply add one of `#[get]`, `#[post]`, etc on top of your function. This function has a few restrictions - it must:

* Be an async function
* Return a `Result<T, E>`
* Take arguments that are either `Serialize + Deserialize` *or* `IntoRequest + FromRequest`
* Return a type that is either `Serialize + Deserialize` *or* `IntoResponse + FromResponse`

Dioxus uses some specialization "magic" to enable flexible input and output types, so the errors for types not satisfying these bounds might be rather unwieldy.

In essence, the non-URL inputs must either be a set of items that are obviously serializable (think strings, numbers, custom types):

````rust
// The function inputs create a single serializable object that looks like:
//
// ```
// #[derive(Serialize, Deserialize)]
// struct Body {
//     a: String,
//     b: i32,
//     c: serde_json::Value,
// }
// ```
#[get("/api/json-body")]
async fn json_body(a: String, b: i32, c: serde_json::Value) -> Result<()> {
	Ok(())
}
````

*or*, the inputs would be a single object that implements Axum's `FromRequest` trait and Dioxus' `IntoRequest` trait. Dioxus Fullstack provides a number of built-in types that implement these types and can be used across the client and the server:

````rust
// The `FileStream` type lets us stream file uploads from the client to the server
#[get("/api/upload")]
async fn upload(file: FileStream) -> Result<()> {
	// ....
}
````

Similarly, the output type can be either a serializable object (strings, numbers, custom structures)

````rust
// Our custom payload implements `Serialize + Deserialize`
#[derive(Serialize, Deserialize)]
struct Payload {
	a: i32,
	b: String
}

#[get("/api/json-out")]
async fn json_body() -> Result<Payload> {
	Ok(Payload {
		a: 123,
		b: "hello".to_string(),
	})
}
````

*or* an object that implements Axum's `IntoResponse` trait and Dioxus' `FromResponse` trait. Many built-in types implement these traits and can be returned to the client:

````rust
#[get("/api/stream")]
async fn stream() -> Result<Streaming<String>> {
	// ...
}
````

If you want to use a 3rd-party Axum response type but it doesn't implement `FromResponse`, then you need to call `.into_response()` and return an `axum::response::Response` type instead:

````rust
#[get("/api/video", range: RangeHeader)]
async fn video_endpoint() -> Result<axum::response::Response> {
	let chunk = get_chunk_from_range(range);
	Ok(chunk.into_response())
}
````

### Path and Query Extractors

We can combine custom payload bodies with query and path extractors, enabling us to build APIs that are suitable both for our Rust frontend and any other HTTP client. This can be particularly useful if your API is consumed both by your own app and external customers.

To add query and path extractors, we can use the Axum route syntax in the macro. The macro will parse the route and generate the associated axum extractors for you:

````rust
#[get("/api/products/{product}?color&quantity")]
async fn get_product_data(product: String, color: String, quantity: Option<i32>) -> Result<Vec<Product>> {
	// ...
}
````

Under the hood, we generate `axum::extract::Query<T>` and `axum::extract::Path<T>` objects, so you can use any valid types, like `Option<T>`. When extracting from the URL, values are URL-encoded and URL-decoded. Note that not all structures can be cleanly URL-encoded, so we recommend sticking with simple data types where possible.

We can combine path and query extractors with the body extractor. This is especially useful when sending additional data alongside custom payloads.

````rust
// we can pass along additional data to objects like streams!
#[post("/api/photos/upload?name&rating")]
async fn upload_photo(name: String, rating: i32, image: FileStream) -> Result<i32> {
	// ...
}
````

### Custom Inputs

We mentioned earlier that the non-query arguments of a server function must be one of two types:

* A group of serializable types (strings, ints, custom serializable structs)
* A single type that implements `FromRequest` and `IntoRequest`

The second type - `FromRequest + IntoRequest` - is extremely powerful. This lets us create new bodies that abstract over the client request with Rust methods, making things like the built-in `WebsocketOptions` and `Websocket` types possible.

````rust
#[get("/api/ws")]
async fn get_updates(options: WebsocketOptions) -> Result<Websocket> {
	Ok(options.on_upgrade(|mut socket| {
		// ...
	}))
}
````

The `WebsocketOptions` type implements the two key Rust traits mentioned above: `FromRequest` and `IntoRequest`.

The first trait, [`FromRequest`](https://docs.rs/axum/latest/axum/extract/trait.FromRequest.html), comes from Axum, the library that Dioxus fullstack is built on.

To implement the `FromRequest` trait, we need to define our new type and then implement the `from_request` method. If you aren't sure which `Rejection` type to use in the implementation, you can use the built-in `ServerFnError` type which integrates with the rest of Dioxus fullstack.

````rust
struct WebsocketOptions {}

impl<S: Send> FromRequest<S> for WebSocketOptions {
    type Rejection = axum::response::Response;

    fn from_request(
        request: Request,
        state: &S,
    ) -> impl Future<Output = Result<Self, Self::Rejection>> + Send {
		async move {
			// .. implementation for our type
		}
	}
}
````

Implementing `FromRequest` lets us use `WebsocketOptions` type as an Axum extractor. Now, we need to implement `IntoRequest` which lets create `WebsocketOptions` on the client before passing it off to the server.

The `IntoRequest` trait is generic over a hidden "state" type parameter. Generally, you'll implement the plain `IntoRequest` type, but for complex types like Websockets, we need a custom state object that the response (`Websocket`) will use to initialize with. In this case, we create a new state type called `UpgradingWebsocket` which will hold the state from the original request to properly upgrade the server's response into a `Websocket` handle.

````rust
struct UpgradingWebsocket {
	/// .. state for the connection
}

// IntoRequest is generic over `UpgradingWebsocket`
impl IntoRequest<UpgradingWebsocket> for WebSocketOptions {
    fn into_request(
        self,
        request: ClientRequest,
    ) -> impl Future<Output = std::result::Result<UpgradingWebsocket, RequestError>> + 'static {
		async move {
			let stream = send_request(request).await?;

			return Ok(UpgradingWebsocket {
				// ... pass along the stream
			})
		}
	}
}
````

For bodies that don't need custom state, you can just use the default `IntoRequest` type which is generic over the Dioxus Fullstack `ClientResponse` type

````rust
// the default state is `ClientResponse`:
pub trait IntoRequest<R = ClientResponse>: Sized {
    fn into_request(
        self,
        req: ClientRequest,
    ) -> impl Future<Output = Result<R, RequestError>> + 'static;
}
````

Now, when the client makes a request to our endpoint, the `WebsocketOptions` struct can be used to store state for the connection:

````rust
// We can now use `WebsocketOptions` as a custom body:
#[get("/api/ws/")]
async fn get_updates(options: WebsocketOptions) -> Result<()> {
	// ...
}

// Calling the endpoint is still quite simple:
_ = get_updates(WebsocketOptions::new()).await?;
````

### Custom Outputs

The `IntoRequest` and `FromRequest` traits allow us to send arbitrary data types to the Server, but sometimes we need to return arbitrary data types to the Client. In our example above, this would be the `Websocket` return type:

````rust
#[get("/api/ws")]
async fn get_updates(options: WebsocketOptions) -> Result<Websocket> {
	Ok(options.on_upgrade(|mut socket| {
		// ...
	}))
}
````

As mentioned above, the return type of a server function must be one of two types:

* An obviously serializable object (string, int, custom struct)
* A type that implements `IntoResponse` and `FromResponse`

The [`IntoResponse`](https://docs.rs/axum/latest/axum/response/trait.IntoResponse.html) trait comes from Axum and is quite simple to implement. To implement the `IntoResponse` trait, we just need to implement the `into_response` method for our custom type. The return type here is an Axum `Response` which is very simple to construct:

````rust
impl IntoResponse for Websocket {
	fn into_response(self) -> Response {
        Response::builder()
			.status(200)
			.header(/* */)
			.body(/* */)
			.unwrap()
	}
}
````

The Response here is directly passed along to the client. Dioxus Fullstack might attach some additional headers to the response, but the response body will remain untouched as its returned through the Axum router.

Now, to use our `Websocket` type on the client, we need to implement `FromResponse`. The `FromResponse` trait is an analog to the `IntoResponse` trait, with a similar definition:

````rust
pub trait FromResponse<R = ClientResponse>: Sized {
    fn from_response(res: R) -> impl Future<Output = Result<Self, ServerFnError>>;
}
````

Just like `IntoRequest`, the `FromResponse` trait is generic over a default state parameter (usually `ClientResponse`). For our `Websocket` type, we need to match the same state parameter as our `WebsocketOptions` type. Usually, we *aren't* generic over the state parameter since the `ClientResponse` type is quite useful on its own, but for `Websocket`, we want to make sure the input request has the required state at compile time.

To implement `FromResponse`, we need to create a new instance of our type from the stored state:

````rust
impl FromResponse<UpgradingWebsocket> for Websocket {
    fn from_response(res: UpgradingWebsocket) -> impl Future<Output = Result<Self, ServerFnError>> {
		async move {
			// ...
		}
	}
}
````

Note that the error type here is `ServerFnError`. This type ensures that the client code can properly downcast any errors that occur while making the request into a standard error type. The `ServerFnError` type includes a number of useful error variants, allowing us to express all sorts of failure modes, some with a standardized HTTP status code and details.

### Server Extractors

As you build increasingly complex backends, you might need more control over extracting data from the request. This could be handling things like auth tokens, cookies, range headers, or any number of tasks related to the request and its headers. Sometimes, these values cannot be sent directly from the client.

In the case of authentication, we might want to extract a stateful extension from the request or reader a specific header like the auth-bearer. In many cases, the client does not explicitly pass these types to the server as they are either extracted using server-only state or implicitly attached like cookies.

To extract arbitrary data from the request, we can "hoist" the function arguments into the macro. The types here must implement Axum's `FromRequestParts` trait - or `FromRequest` if there's no client-only body.

````rust
// Our `auth` argument is a function argument hoisted to the argument list in the proc macro
#[post("/api/user/login", auth: auth::Session)]
pub async fn login() -> Result<()> {
    auth.login_user(2);
    Ok(())
}
````

Because the types here must implement `FromRequestParts`, we can use a wide variety of built-in extractors. For example, we can extract the entire `HeaderMap` object from the request:

````rust
#[get("/api/headers", headers: dioxus::fullstack::HeaderMap)]
async fn get_headers() -> Result<String> {
    Ok(format!("{:#?}", headers))
}
````

We can stack as many of these extractors as we'd like:

````rust
#[post("/api/user/login", header: TypedHeader<Cookie>, auth: Session)]
pub async fn login() -> Result<()> {
    // ...
}
````

Server-only extractors make it easy to migrate existing axum handlers to Server Functions without too many code modifications.

## Handling Errors

### Acceptable Error Types

By default, Dioxus exports a custom `Result<T>` type in the prelude. Whenever you call `use dioxus::prelude::*`, you import this `Result<T>` type into the module's scope. This `Result<T>` type is actually a re-export of anyhow's `Result<T>` type.

Anyhow's Result type is a widely used "dynamic" error type used in Rust applications. It is extremely flexible, allowing you to use Rust's powerful question-mark (`?`) syntax with any error type that implements `std::Error`.

This means that the above examples are equivalent to using the anyhow error type directly:

````rust
#[post("/api/user/login")]
pub async fn login() -> Result<(), anyhow::Error> {
    // ...
}
````

Unfortunately, when errors are created on the server, Dioxus Fullstack cannot preserve the error's type on the client. Therefore, all errors from endpoints that use the plain `Result<T>` will always downcast to the Dioxus Fullstack `ServerFnError` type:

````rust
// Make the request, assuming it always fails, unwrapping the error
let res = login().await.unwrap_err();

// We can only downcast this error to `ServerFnError`
let error = res.downcast_ref::<ServerFnError>().unwrap();
````

If you want more detail about the error type, you can use the `ServerFnError` type directly, or use `ServerFnResult`:

````rust
#[post("/api/user/login")]
pub async fn login() -> Result<(), ServerFnError> {
    // ...
}
````

The `ServerFnError` type is a special error type that integrates cleanly with the rest of Dioxus. Its many variants represent various failure points of handling a given request. Its two most important variants are `ServerError` and `RequestError`.

````rust
pub enum ServerFnError {
    /// Occurs when there is an error while actually running the function on the server.
    #[error("error running server function: {message} (details: {details:#?})")]
    ServerError {
        /// A human-readable message describing the error.
        message: String,

        /// HTTP status code associated with the error.
        code: u16,

		/// Serialized custom error type
        details: Option<serde_json::Value>,
    },

    /// Occurs on the client if there is a network error while trying to run function on server.
    #[error("error reaching server to call server function: {0} ")]
    Request(RequestError),

	// ...
}
````

If an endpoint returns a `ServerFnError`, you can match the result on the client, providing more useful feedback to the user in the event of a failure:

````rust
match login().await {
	Err(ServerFnError::ServerError { code, .. }) => {
		if code == 404 {
			// .. handle not found
		}

		if code == 401 {
			// .. handle unauthorized
		}
	}
	_ => { /* */ }
}
````

Endpoints can accept a wide variety of error types, including:

* `anyhow::Error`: a simple, flexible error type to build quickly
* `ServerFnError`: a structured error for granularly handling types of errors
* `StatusCode`: a simple wrapper around the HTTP status code
* `HttpError`: the error type returned from the `OrHttpError` type
* Custom Errors: user-defined errors (see below)

### Custom Errors

In addition to `anyhow::Error`, `ServerFnError`, and `HttpError`, Server Functions can return custom, user-defined errors. These errors must implement `Serialize`, `Deserialize`, and an additional trait called `AsStatusCode`. `AsStatusCode` requires the error implement `From<ServerFnError>` and a method to get the actual status code from the error itself.

You can easily create new error types using the `thiserror` crate's `Error` macro. The `#[from]` attribute makes it possible to easily convert `ServerFnError` into the custom error type.

````rust
#[derive(thiserror::Error, Debug, Serialize, Deserialize)]
enum MyCustomError {
    #[error("bad request")]
    BadRequest { custom_name: String },

    #[error("not found")]
    NotFound,

    #[error("internal server error: {0}")]
    ServerFnError(#[from] ServerFnError),
}
````

We must then implement `AsStatusCode` so Dioxus Fullstack knows which status code to return to the client in the event of an error.

````rust
impl AsStatusCode for MyCustomError {
    fn as_status_code(&self) -> StatusCode {
        match self {
            MyCustomError::BadRequest { .. } => StatusCode::BAD_REQUEST,
            MyCustomError::NotFound => StatusCode::NOT_FOUND,
            MyCustomError::ServerFnError(e) => e.as_status_code(),
        }
    }
}
````

### Ergonomic Error Handling

Dioxus Fullstack provides a utility trait called `OrHttpError` to convert common failure cases into proper HTTP status codes and error messages. This trait makes it simpler to follow proper web semantics (like 404 for not-found, 401 for not-authorized, etc) while keeping inline with ergonomic Rust error handling.

You can use `OrHttpError` methods on any `Result<T>`, `Option<T>`, or `bool`, to return an `Err(HttpError)`.

For example, we might write an `authorize` method that throws an error if authorization fails. We can use the method `or_unauthorized()?` to convert the error into an appropriate status code.

````rust
#[post("/api/user/login")]
pub async fn login() -> Result<(), ServerFnError> {
	authenticate_user()
		.or_unauthorized("You must be logged in to view this resource")?;
	// ..
}
````

To prevent polluting the global scope, only a few utility methods are available by default. You can use the `or_http_error` to return any status code:

````rust
#[post("/api/user/login")]
pub async fn login() -> Result<(), ServerFnError> {
	authenticate_user()
		.or_http_error(StatusCode::UNAUTHORIZED, "Log in first!")?;
	// ..
}
````

Note that even when we use `anyhow::Error`, Dioxus will automatically extract the appropriate status code from the error:

````rust
// our `Result<T>` contains an `HttpError` object
#[post("/api/user/login")]
pub async fn login() -> Result<()> {
	authenticate_user()
		.or_http_error(StatusCode::UNAUTHORIZED, "Log in first!")?;
	// ..
}
````

This is true for `HttpError`, `StatusCode`, and `ServerFnError`, all of which are downcasted from the anyhow Error type.
# Fullstack Error Handling

Errors are unfortunately inevitable in software development. Even in Rust, apps might not behave as expected and user requests might be malformed.

In these cases, you might want to show an error page to the user while also returning an appropriate status code.

## Creating an Error

Recall in the [Server Functions](./server_functions.md) chapter, that all server functions must return a `Result<T>`:

````rust
#[post("/api/user/login")]
pub async fn login() -> Result<()> {
    // ...
}
````

Because server functions are called from the client, they need some way of expressing *both* a request failure and a server failure. If the user is offline, we want to reliably return an offline error and status in the UI.

Also recall that server functions can return several different error types:

* `ServerFnError`: A broad error type encompassing request failures and server failures
* `anyhow::Error`: A general-purpose error type that downcasts its inner value
* `CapturedError`: A cheaply-cloneable `anyhow::Error` wrapper
* `StatusCode`: A specific HTTP status code
* `HttpError`: A specific HTTP status code and a message
* Custom Errors: User errors that implement `Serialize + Deserialize + AsStatusCode`

Dioxus will attempt to downcast server function errors and captured errors into status codes such that the returned page receives an appropriate HTTP status.

If an error does not downcast to a known status-code-like error type, then the request will default to a `500 INTERNAL SERVER ERROR`.

````rust
#[post("/api/user/login")]
pub async fn login() -> Result<()> {
    // This will return a 500 status code
    return Err(anyhow::anyhow!("Bad request!").into());

    // ...
}
````

The `OrHttpError` error type makes emitting status codes quite simple with its extension methods on `Result<T>`, `Option<T>`, and `bool`.

````rust
#[post("/api/user/login")]
pub async fn login() -> Result<()> {
	authenticate_user()
        // this method comes from `OrHttpError`
		.or_unauthorized("You must be logged in to view this resource")?;
	// ..
}
````

## Error Status Codes Bubble

In the event of an error, Dioxus extracts the status code for the response by downcasting errors that bubble to root component.

For example, this example app does not provide a root error boundary, and thus all errors will bubble up to the root:

````rust
fn app() -> Element {
    let post_data = use_loader(move || get_post())?;

    rsx! {
        p { "{post_data}" }
    }
}

// This endpoint always throws an error
#[get("/api/post/")]
async fn get_post() -> Result<String, HttpError> {
    HttpError::not_found("Post not found")
}
````

If you `curl` the app, you'll notice that it returns a `404` status code.

If we want to catch the error and provide a nice fallback UI, we can use an `ErrorBoundary`. Note that when we catch the error, we must explicitly set the HTTP status code on the outgoing response with `FullstackContext::commit_error_status`:

````rust
fn app() -> Element {
    rsx! {
        ErrorBoundary {
            handle_error: move |err| {
                // To ensure the HTTP status is still set properly, we need to call `commit_error_status`
                let http_error = FullstackContext::commit_error_status(err.error().unwrap());

                // and then we can render some pretty fallback UI
                rsx! { "An error occurred! {http_error:?}" }
            },
            Post {}
        }
    }
}

fn Post() -> Element {
    let post_data = use_loader(move || get_post())?;
    rsx! { p { "{post_data" } }
}
````

The `commit_error_status` function on `FullstackContext` extracts the HTTP status from a `CapturedError` and then modifies the outgoing response accordingly.

## Error Layout with Router

If you're using the Dioxus Router for your app's routing, then it might not be immediately clear how to integrate custom error pages into your app.

In these cases, we'd take a similar approach with an `ErrorBoundary`. We could either wrap our `Router {}` component in an error boundary, or add a layout to our app that renders the fallback UI.

````rust
// A router definition with `ErrorLayout` layout
#[derive(Routable, PartialEq, Clone, Debug)]
enum Route {
    #[layout(ErrorLayout)]
    #[route("/")]
    Home,

    #[route("/blog/:id")]
    Blog { id: u32 },
}

// And then our Outlet is wrapped in a fallback UI
#[component]
fn ErrorLayout() -> Element {
    rsx! {
        ErrorBoundary {
            handle_error: move |err: ErrorContext| {
                let http_error = FullstackContext::commit_error_status(err.error().unwrap());
                match http_error.status {
                    StatusCode::NOT_FOUND => rsx! { div { "404 - Page not found" } },
                    _ => rsx! { div { "An unknown error occurred" } },
                }
            },
            Outlet::<Route> {}
        }
    }
}
````

Using layouts for error pages is extremely powerful. You can isolate fallback UI to specific parts of the page while also properly setting the returned status code.

For example, the GitHub UI retains most of its UI while isolate the 404 message to just the source code viewer:

![Github Fallback UI](/assets/07/github-fallbackui.avif)

It's a better user experience to render a web page that is visually consistent while also still delivering the appropriate status code.
# Axum Router

Dioxus fullstack is built on the popular backend crate Axum. The default `dioxus::launch` function will initialize a default Axum server for your fullstack project. If you need more control, you can easily customize the router with `dioxus::serve`.

The `dioxus::serve` function is the primary entrypoint for Dioxus apps that run on the server, as is standard in fullstack applications. For fullstack apps, you'll typically use both `dioxus::launch` and `dioxus::serve`, enabling each entrypoint based on the `"server"` feature.

````rust
fn main() {
    // Run `serve()` on the server only
    #[cfg(feature = "server")]
    dioxus::serve(|| async move {
        // Create a new router for our app using the `router` function
        let mut router = dioxus::server::router(app);

        // .. customize the router, adding layers and new routes

        // And then return the router
        Ok(router)
    });

    // When not on the server, just run `launch()` like normal
    #[cfg(not(feature = "server"))]
    dioxus::launch(app);
}
````

Note how we use Rust's built-in `#[cfg]` macro to conditionally launch the app based on the `server` feature. When `server` feature is enabled, we enable `dioxus::serve`, and when it is disabled, we enable `dioxus::launch`.

The `dioxus::server::router` function creates a new axum router that sets up a few important pieces:

* Static Assets: automatically serve the `public` directory, index.html and assets
* SSR: automatically run the app, render it to HTML, and serialize data for hydration
* Server Functions: automatically initialize the API endpoints

Dioxus uses extension methods on the Axum router (given by `DioxusRouterExt`) that is equivalent to enabling each of these items manually:

````rust
axum::Router::new()
	.register_server_functions()
	.serve_static_assets()
	.fallback(
		get(render_handler).with_state(RenderHandleState::new(cfg, app)),
	)
````

## Registering Server Functions

When you use `dioxus::server::router` or `dioxus::launch` to start your fullstack server, Dioxus Fullstack registers all server functions for you automatically. This means you can quickly build your backend without needing to explicitly wire up endpoints to a central router.

If you need more control with a custom axum setup, you can manually iterate through the list of global server functions and register single endpoints, or create new routers with a subset of routes with `ServerFunction::collect()`:

````rust
// We can iterate through all server functions:
for func in ServerFunction::collect() {
	// Read their data
	tracing::info!(
		"Registering server function: {} {}",
		func.method(),
		func.path()
	);

	// And add them to our router
	router = func.register_server_fn_on_router(router);
}
````

## Adding New Routes

One common use-case of a custom axum router is to add new routes to the router that are *not* defined with server functions. We might want to include special endpoints that respond dynamically or that return non-HTML data types.

This example adds three new routes to our app:

````rust
dioxus::serve(|| async move {
    use dioxus::server::axum::routing::{get, post};

    let router = dioxus::server::router(app)
        .route("/submit", post(|| async { "Form submitted!" }))
        .route("/about", get(|| async { "About us" }))
        .route("/contact", get(|| async { "Contact us" }));

    Ok(router)
});
````

Note that the server-side-rendering handler is registered as a *fallback* handler. Any routes we manually register will take priority over the Dioxus app. Since these handlers are axum handlers, they can take the typical modifiers, like `.with_state()`, `.layer()`, etc.

````rust
let router = dioxus::server::router(app)
    .route(
        "/submit",
        post(
            |state: State<FormSubmitter>, ping: Extension<Broadcast>, cookie: TypedHeader<Cookie>| async {
                // ... endpoint logic
            },
        ),
    )
    .with_state(FormSubmitter::new())
    .layer(Extension(Broadcast::new()));
````

The [Axum documentation](https://docs.rs/axum/latest/axum/index.html) has more information on defining routes and handlers outside of server functions.

## Adding `Layers`

Axum allows you to to attach middleware to many parts of your router:

* To entire routers with [Router::layer](https://docs.rs/axum/latest/axum/struct.Router.html#method.layer) and [Router::route_layer](https://docs.rs/axum/latest/axum/struct.Router.html#method.route_layer).
* To method routers with [MethodRouter::layer](https://docs.rs/axum/latest/axum/routing/method_routing/struct.MethodRouter.html#method.layer) and [MethodRouter::route_layer](https://docs.rs/axum/latest/axum/routing/method_routing/struct.MethodRouter.html#method.route_layer).
* To individual handlers with [Handler::layer](https://docs.rs/axum/latest/axum/handler/trait.Handler.html#method.layer).

## Adding State with Extensions

As you build out your app, you might want to expose state to your endpoints and to your requests. Axum provides two ways of adding state to endpoints: `Extension` and `State<T>`. Extensions enable you to attach extra data to requests as they are handled by your router.

You can use extensions *either* as a form of global state *or* as a way of attaching state to requests. To share a given piece of data with all endpoints, you can attach the extension as a layer to the router in `dioxus::serve`:

````rust
dioxus::serve(|| async move {
    use dioxus::server::axum::Extension;
    use tokio::sync::broadcast;

    let router = dioxus::server::router(app)
        .layer(Extension(broadcast::channel::<String>(16).0));

    Ok(router)
});
````

Now, in our handlers, we can extract the extension from the request:

````rust
#[post("/api/broadcast", ext: Extension<broadcast::Sender<String>>)]
async fn broadcast_message() -> Result<()> {
    ext.send("New broadcast message".to_string())?;
    Ok(())
}
````

If we want to attach state to a single request - as in the case with a session middleware - we can attach a new middleware to the router that dynamically inserts a new extension into the request.

````rust
use axum::{extract::Request, middleware::Next, middleware};

let router = dioxus::server::router(app)
    .layer(middleware::from_fn(|req: Request, next: Next| async move {
        // Attach some extra state to the request
        req.extensions_mut().insert(Session::new());

        // And then return the response with `next.run()
        Ok::<_, Infallible>(next.run(req).await)
    }))
````

## Using `Lazy<T>` as Global State

As a simpler alternative to axum extensions and `State<T>`, you can also use the built-in `Lazy<T>` type to access server resources without needing to set up a dedicated `dioxus::serve` entrypoint. The `Lazy<T>` type is very similar to the standard library's `LazyLock<T>` type, making it possible to initialize asynchronous data like database connections.

Simply create a new `Lazy<T>` instance as a `static` variable:

````rust
static DATABASE: Lazy<sqlx::SqlitePool> = Lazy::new(|| async move {
    dioxus::Ok(
        SqlitePoolOptions::new()
            .max_connections(5)
            .connect_with("sqlite::memory:".parse().unwrap())
            .await?,
    )
});
````

Then when you access the `DATABASE` object in your code, Dioxus will ensure it's properly initialized, blocking the current thread until the initializer finishes. This lets you use asynchronous resources *synchronously* which makes them extremely ergonomic.

````rust
/// When using the `Lazy<T>` type, it implements `Deref<Target = T>`, so you can use it like a normal reference.
#[get("/api/users")]
async fn get_users() -> Result<Vec<String>> {
    let users = DATABASE
        .fetch_all(sqlx::query("SELECT name FROM users"))
        .await?
        .iter()
        .map(|row| row.get::<String, _>("name"))
        .collect::<Vec<_>>();

    Ok(users)
}
````

Typically, Rust discourages the use of global variables for managing state, but for apps like web-servers, it's generally okay to have a single shared object for the entire app.

Note that you can also use the built-in standard `LazyLock` type for simple synchronous data:

````rust
static MESSAGES: LazyLock<Mutex<Vec<String>>> = LazyLock::new(|| Mutex::new(Vec::new()));

#[post("/api/messages")]
async fn add_message() -> Result<()> {
    MESSAGES.lock().await.push("New message".to_string());
    Ok(())
}
````
# Middleware

Middleware allows you to run code before a request is completed. Then, based on the incoming request, you can modify the response by rewriting, redirecting, modifying the request or response headers, or responding directly.

Dioxus Fullstack provides two main ways of adding middleware to your app:

* Imperatively using Axum's APIs on your Router in `dioxus::serve`
* Declaratively by annotating individual endpoints with the `#[middleware]` attribute

## What is Middleware?

In web applications, middleware are functions that are called before and after the request is handled by your endpoint logic.

The underlying web framework that Dioxus Fullstack is built on - Axum - does not define its own bespoke middleware system. Instead, it leans on the broader ecosystem, integrating with the more fundamental [`tower`](https://github.com/tower-rs/tower) and [`hyper`](https://github.com/hyperium/hyper) crates.

Axum *does* provide a simple way of writing middleware with `middleware::from_fn`:

````rust
axum::middleware::from_fn(
    |request: Request, next: Next| async move {
        // Read and write the contents of the incoming request
        println!("Headers: {:?}", request.headers());

        // And then run the request, modifying and returning the response
        next.run(request).await
    },
)
````

Middleware give you both *read* and *write* access to both the *request* and the *response* of the handler. This is extremely powerful!

You can implements a wide range of functionality with middleware:

* Logging and telemetry
* Rate limiting
* Validation
* Compression
* CORS, CSRF
* Authentication and Authorization
* Caching

The broader Rust ecosystem has many different 3rd party crates for middleware.

The two main crates to look for middleware are:

* [Tower](https://docs.rs/tower/latest/tower/): The underlying library for networking
* [Tower-HTTP](https://github.com/tower-rs/tower-http): A dedicated HTTP-specific middleware library

## Middleware on the Router

Because Dioxus is built on Axum, you can use many Axum APIs directly. Dioxus Fullstack does not provide any bespoke wrappers around Axum middleware - you can simply attach them to your router in `dioxus::serve`:

````rust
dioxus::serve(|| async move {
    use axum::{extract::Request, middleware::Next};
    use dioxus::server::axum;

    Ok(dioxus::server::router(app)
        // we can apply a layer to the entire router using axum's `.layer` method
        .layer(axum::middleware::from_fn(
            |request: Request, next: Next| async move {
                // Read the incoming request
                println!("Request: {} {}", request.method(), request.uri().path());

                // Run the handler, returning the response
                let res = next.run(request).await;

                // Read/write the response
                println!("Response: {}", res.status());

                res
            },
        )))
});
````

The Tower-HTTP crate provides a number of useful middleware layers to add to your app. The `ServiceBuilder` object can be used to efficiently assemble a `Service` which handles a wide range of middleware actions:

````rust
// Use tower's `ServiceBuilder` API to build a stack of tower middleware
// wrapping our request handler.
let middleware = ServiceBuilder::new()
    // Mark the `Authorization` request header as sensitive so it doesn't show in logs
    .layer(SetSensitiveRequestHeadersLayer::new(once(AUTHORIZATION)))
    // High level logging of requests and responses
    .layer(TraceLayer::new_for_http())
    // Share an `Arc<State>` with all requests
    .layer(AddExtensionLayer::new(Arc::new(state)))
    // Compress responses
    .layer(CompressionLayer::new())
    // Propagate `X-Request-Id`s from requests to responses
    .layer(PropagateHeaderLayer::new(HeaderName::from_static("x-request-id")))
    // If the response has a known size set the `Content-Length` header
    .layer(SetResponseHeaderLayer::overriding(CONTENT_TYPE, content_length_from_response))
    // Authorize requests using a token
    .layer(ValidateRequestHeaderLayer::bearer("passwordlol"))
    // Accept only application/json, application/* and */* in a request's ACCEPT header
    .layer(ValidateRequestHeaderLayer::accept("application/json"))
    // Wrap a `Service` in our middleware stack
    .service_fn(handler);
````

You can then attach this service as a layer to your router:

````rust
dioxus::serve(|| async move {
    use axum::{extract::Request, middleware::Next};
    use dioxus::server::axum;

    // Assemble a middleware object from the ServiceBuilder
    let middleware = ServiceBuilder::new()
        .layer(/* */)
        .layer(/* */)
        .layer(/* */);

    Ok(dioxus::server::router(app).layer(middleware))
});
````

Axum recommend initializing multiple middleware on a `ServiceBuilder` object for maximum performance, but you can also attach layers directly onto the router:

````rust
dioxus::serve(|| async move {
    use axum::{extract::Request, middleware::Next};
    use dioxus::server::axum;

    Ok(
        dioxus::server::router(app)
            .layer(/* */)
            .layer(/* */)
            .layer(/* */)
    )
});
````

## Middleware on individual Routes

If you need to apply middleware to just a handful of specific routes, you can use the `#[middleware]` attribute. Unlike router-level middleware, route-level middleware will only be applied to a specific endpoint. Alternatively, you could register routes one-by-one on the axum router with dedicated calls `.layer()`.

For example, we might want to add a "timeout" middleware to a specific server function. This middleware will stop running the server function if it reaches a certain timeout:

````rs@server_function_middleware.rs
#[cfg(feature = "server")]
use {std::time::Duration, tower_http::timeout::TimeoutLayer};

// Add a timeout middleware to the server function that will return an error if the function takes longer than 1 second to execute
#[post("/api/timeout")]
#[middleware(TimeoutLayer::new(Duration::from_secs(1)))]
pub async fn timeout() -> Result<(), ServerFnError> {
    tokio::time::sleep(Duration::from_secs(2)).await;
    Ok(())
}
````

Under the hood, Dioxus Fullstack creates a `MethodRouter` object and then attaches these layers with calls to `.layer()` automatically.

## Caching and Middleware

In the chapter on server-side-rendering, we discussed at length about how Dioxus Fullstack is architected around client-side-rendering, with SSR being an additional enhancement. One enhancement is the ability to add a `Cache-Control` header to HTML responses, letting our CDN and Reverse Proxy decrease the load on our server. When the `Cache-Control` header is present, the proxy is able to cache responses.

 > 
 > It's very important to note that middleware can "bust" the cache - even accidentally!

If you're using middleware for session management or authentication, it can be easy to accidentally cache pages that shouldn't be cached. For example, a news site might want to cache its homepage:

````rust
dioxus::server::router(app)
    .layer(axum::middleware::from_fn(
        |request: Request, next: Next| async move {
            // If the route is `/home`, cache the page
            let is_home = request.uri() == "/home";

            let res = next.run(request).await;

            if is_home {
                res.headers_mut().insert("Cache-Control", "max-age=10800")
            }

            res
        }
    ))
````

Eventually, we might add a feature that lets users customize their homepage. We might add a session layer to our router:

````rust
dioxus::server::router(app)
    .layer(session_layer) // a new session layer
    .layer(caching_layer)
````

If we're not careful, we might accidentally cache a *logged-in user's* homepage! Caching is typically based on the request's URL, but middleware also operate on headers. If we show dynamic content based on headers (like auth or sessions), we need to take care to only cache certain responses.

Many reverse proxies have the ability to configure caching based on request headers. We suggest diving into our deploy platform's reverse proxy setup, or implementing a smarter caching middleware yourself.
# Websockets

Dioxus Fullstack provides built-in types for creating and managing websockets that work alongside server functions. Dioxus websockets are built on top of the underlying Axum websocket API, but with a few improvements tailored for fullstack apps:

* Shared server/client types
* Reactive wrappers for use in UI code
* Typed inputs, outputs, and customizable encoding

Websockets are an extremely powerful communication protocol that allows bidirectional message passing to and from the server. Websockets are more efficient than HTTP requests for large amounts of messages, provide better real-time support, and allow for *ordered* data transmission.

Note that websockets are *stateful*, meaning that a websocket connection ties a client and server together for a given session. If you plan to use websockets in a "serverless" environment with time limits of request handling, then you need some way to "store" the websocket session across multiple requests.

## Websocket and WebsocketOptions

To create a new server function that returns a websocket, simply use `WebsocketOptions` as your body type and `Websocket` as your response type.

````rust
#[get("/api/uppercase_ws")]
async fn uppercase_ws(options: WebSocketOptions) -> Result<Websocket> {
    Ok(options.on_upgrade(move |mut socket| async move {
        // send back a greeting message
        _ = socket
            .send("Hello!".to_string())
            .await;

        // Loop and echo back uppercase messages
        while let Ok(msg) = socket.recv().await {
            _ = socket.send(msg.to_ascii_uppercase()).await;
        }
    }))
}
````

The `Websocket` type is generic over three parameters - the input type, output type, and encoding:

````rust
pub struct Websocket<In = String, Out = String, E = JsonEncoding> {
    // ...
}
````

The input and output types are the types used when you call `.send()` and `.recv()` on the `socket` object provided after `on_upgrade`. By strongly typing the websocket, we guarantee that your client and server always use the right message format across the client and server.

The `on_upgrade` method is a wrapper over the underlying Axum `on_upgrade` API that returns an axum response, indicating to the client that the websocket upgrade process is successful. If the client agrees, then the server will run the `on_upgrade` callback, spawning the future. Note that this future is spawned on a tokio [LocalSet](https://docs.rs/tokio/latest/tokio/task/struct.LocalSet.html). This means the future does not need to be `Send`.

We can use our own message types for the input and output messages. Calls to `.send()` and `.recv()` will attempt to deserialize messages into the right type, returning an error if the deserialization fails.

````rust
// Events flowing *from* the client to the server
#[derive(Serialize, Deserialize, Debug)]
enum ClientEvent {
    TextInput(String),
}

// Events flowing *to* the client from the server
#[derive(Serialize, Deserialize, Debug)]
enum ServerEvent {
    Uppercase(String),
}

#[get("/api/uppercase_ws")]
async fn uppercase_ws(options: WebSocketOptions) -> Result<Websocket<ClientEvent, ServerEvent>> {
    // ...
}
````

We can also customize the encoding of the websocket with the third generic on `Websocket`. By default, messages are encoded using JSON with `JsonEncoding`, but you can opt for an alternative format like the binary Cbor format with `CborEncoding`:

````rust
#[get("/api/uppercase_ws")]
async fn uppercase_ws(options: WebSocketOptions) -> Result<Websocket<ClientEvent, ServerEvent, CborEncoding>> {
    // ...
}
````

Generally, if you're working with Rust-only clients, then Cbor or MsgPack are better options, but 3rd-party clients might be better suited with the standard JSON encoding.

If you need to send extra details to the server before establishing the websocket connection, you can use path and query parameters as well as header extraction like usual.

````rust
#[get("/api/uppercase_ws?name&age")]
async fn uppercase_ws(
    name: String,
    age: i32,
    options: WebSocketOptions,
) -> Result<Websocket<ClientEvent, ServerEvent, CborEncoding>> {
    // ...
}
````

## Connecting to a Websocket

On the client, to connect to a websocket, we'll simply call the server function and await the result. You might do this inside a `use_future` hook to connect to the websocket endpoint when the component is mounted:

````rust
// Calling `.recv()` automatically waits for the connection to be established and deserializes
// messages as they arrive.
use_future(move || async move {
    // Connect to the websocket
    let socket = uppercase_ws(WebSocketOptions::new()).await;

    // Wait for the next message with `.recv()`
    while let Ok(msg) = socket.recv().await {
        messages.push(msg);
    }
});
````

The `Websocket` object has a number of utility methods you can use to assess the state of the connection, send messages, and receive messages. We expose a number of lower-level APIs like `send_raw` that let you send raw websocket frames in case the typed API is too strict.

## The use_websocket hook

You might notice in the `use_future` example above, the websocket is only accessible to its containing scope. In a practical app, you'll want to send messages into the websocket and react to any changes in connection status.

The `use_websocket` hook wraps the `websocket` object with signal-based reactivity. We can use `.status()` to read the websocket connection state, and `.send()` to send messages to the server.

To connect to the websocket, we might use `use_websocket`:

````rust
// The `use_websocket` wraps the `WebSocket` connection and provides a reactive handle to easily
// send and receive messages and track the connection state.
//
// We can customize the websocket connection with the `WebSocketOptions` struct, allowing us to
// set things like custom headers, protocols, reconnection strategies, etc.
let mut socket = use_websocket(|| uppercase_ws("John Doe".into(), 30, WebSocketOptions::new()));
````

To listen for messages, we can use `.recv()` in a future:

````rust
// Calling `.recv()` automatically waits for the connection to be established and deserializes
// messages as they arrive.
use_future(move || async move {
    while let Ok(msg) = socket.recv().await {
        messages.push(msg);
    }
});
````

And then to send messages, we can use `.send()` on the handle:

````rust
rsx! {
    input {
        placeholder: "Type a message",
        oninput: move |e| async move {
            _ = socket.send(ClientEvent::TextInput(e.value())).await;
        },
    }
}
````

If the connection fails, you can restart it by manually calling `.set()` on the handle with a new websocket object.
# Streams and SSE

Dioxus Fullstack provides an easy way to send and receive streaming data from a server. This can be useful to
implement functionality like streaming LLM responses, file downloads, and server-sent-events (SSE).

Unlike websockets which allow two-way communication, streams are unidirectional. In browsers, it's usually impossible to have a streaming input *and* a streaming output, so you should stick to using streams for things like text/byte responses or file sending.

## Streaming Text

Dioxus Fullstack provides the `TextStream` type to easily send chunks of text between the client and the server. We can use this type as the input or output of a server function:

````rust
// The output is a `TextStream`
#[get("/api/test_stream?start")]
async fn text_stream(start: Option<i32>) -> Result<TextStream> {
    let mut count = start.unwrap_or(0);

    // We can create a new text stream with `spawn`
    Ok(TextStream::spawn(move |tx| async move {

        // Send a message with `unbounded_send`
        while tx.unbounded_send(format!("Hello, world! {}", count)).is_ok() {
            count += 1;

            // and then wait a bit
            tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
        }
    }))
}
````

You can create a new stream with `TextStream::spawn` which gives you an `UnboundedSender` object, or from `TextStream::new()` which takes an existing type that implements the `Stream` trait:

````rust
// the `rx` here implements `Stream` which can be used in `new()`
let (tx, rx) = futures::channel::mpsc::unbounded();

tokio::spawn(async move {
    let mut count = start.unwrap_or(0);
    loop {
        let message = format!("Hello, world! {}", count);
        if tx.unbounded_send(message).is_err() {
            break;
        }

        count += 1;
        tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    }
});

Ok(Streaming::new(rx))
````

## Streaming Bytes

The `TextStream` type is a superset of the `ByteStream` type. To send raw bytes between the client and the server, simply use `ByteStream` in the same way as `TextStream`, but with the `Bytes` type as input:

````rust
#[post("/api/upload_as_bytestream")]
async fn upload_as_bytestream(mut stream: ByteStream) -> Result<()> {
    while let Some(chunk) = stream.next().await {
        // ... handle chunk
    }

    Ok(())
}
````

Note that in this example, we are *consuming* the byte stream using `.next()`. Streams in Dioxus implement the standard [`Stream`](https://docs.rs/futures/latest/futures/prelude/trait.Stream.html) trait, which has a number of [useful extensions](https://docs.rs/futures/latest/futures/stream/trait.StreamExt.html).

## The Generic `Streaming<T, E>` type

Both the `TextStream` and `ByteStream` types are implemented as specific variations of the generic `Streaming<T, E>` type. Under the hood, both stream types are simply streams of `Vec<u8>`. The `ByteStream` type wraps the incoming bytes in the `Bytes` type while `TextStream` ensures they're valid utf-8 text.

You can use any encoding provided it implements the `Encoding` trait.

````rust
pub trait Encoding {
    fn content_type() -> &'static str;
    fn stream_content_type() -> &'static str;
    fn to_bytes(data: impl Serialize) -> Option<Bytes>;
    fn from_bytes<O: DeserializeOwned>(bytes: Bytes) -> Option<O>;
}
````

Dioxus provides a number of built-in encodings:

* JsonEncoding: String-encoded JSON text
* CborEncoding: Binary-encoded data in the [CBOR](https://cbor.io) format
* PostcardEncoding: A binary encoding built on [Postcard](https://docs.rs/postcard/latest/postcard/) meant for use in no_std apps
* MsgPackEncoding: A compact binary encoding in a ["JSON but small" format](https://msgpack.org/index.html)

As each element in the stream arrives, it will be appropriately chunked and then deserialized using the encoding's `from_bytes` and `to_bytes` implementations.

This means we can stream arbitrary data - even custom structures!

````rust
#[derive(Serialize, Deserialize, Debug)]
struct Dog {
    name: String,
    age: u8,
}

/// A custom `Streaming<T, E>` endpoint that streams JSON-encoded `Dog` structs to the client.
///
/// Dioxus provides the `JsonEncoding` type which can be used to encode and decode JSON data.
#[get("/api/json_stream")]
async fn json_stream() -> Result<Streaming<Dog, JsonEncoding>> {
    Ok(Streaming::spawn(|tx| async move {
        for count in 0..10 {
            let dog = Dog {
                name: format!("Dog {}", count),
                age: (count % 10) as u8,
            };

            if tx.unbounded_send(dog).is_err() {
                break;
            }

            tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
        }
    }))
}
````

## File Streams

The final stream type, `FileStream`, is a special stream type *not* built on `Streaming<T, E>`. File streams use platform-native optimizations to efficiently stream files without buffering the entire file into memory.

We can create the `FileStream` object in a variety of ways. For example, we can use `from_path` to efficiently stream arbitrary files from the server's file system:

````rust
/// This endpoint uses `file!()` to return the current file's `PathBuf`
#[get("/api/download_as_filestream")]
async fn download_as_filestream() -> Result<FileStream> {
    Ok(FileStream::from_path(file!()).await?)
}
````

The `FileStream` type can be created from the `FileData` type from dioxus-html. This makes it easy to add streaming file uploads to your app from the HTML `<input />` and `<form />` elements:

````rust
// Our client component calls the endpoint with `file.into()`
fn app() -> Element {
    rsx! {
        h3 { "Upload as FileUpload" }
        div {
            ondragover: move |evt| evt.prevent_default(),
            ondrop: move |evt| async move {
                evt.prevent_default();
                for file in files {
                    _ = upload_file_as_filestream(file.into()).await;
                }
            },
            "Drop files here"
        }
    }
}

// Our server endpoint accepts `FileStream`
#[post("/api/upload_as_file_stream")]
async fn upload_file_as_filestream(mut upload: FileStream) -> Result<()> {
    // ...
}
````

The `FileStream` type also sets extra headers like `Content-Disposition` and `X-Content-Size` which give the server endpoint more information to efficiently handle the upload.
# Forms and Multipart

Dioxus natively supports HTML Forms and Multipart uploads.

* HTML forms are collections of input elements represented as a list of key-value pairs
* Multipart requests are requests that contain multiple bodies

Many forms you'll build will be rather simple. Uploading them will only require a single request body. In some cases, as with file-uploads, you'll need a multi-part form data.

## Forms

Dioxus Fullstack supports form uploads through Axum's typed `Form<T>` type. Simply wrap a struct that implements `Serialize + Deserialize` and pass it as an argument to a server function:

````rust
// Our form payload
#[derive(Deserialize, Serialize)]
pub struct LoginForm {
    username: String,
    password: String,
}

// Our form endpoint
#[post("/api/login")]
async fn login(form: Form<LoginForm>) -> Result<()> {
    // Verify the username and password.
    // In a real application, you'd check these against a database.
    if form.0.username == "admin" && form.0.password == "password" {
        // ..
    }
}
````

The values from the form can be created manually by constructing the form body, or automatically by calling `.parsed_values()` on the `FormEvent` type created by `onsubmit`.

````rust
rsx! {
    form {
        onsubmit: move |evt: FormEvent| async move {
            // Prevent the browser from navigating away.
            evt.prevent_default();

            // Extract the form values into our `LoginForm` struct. The `.parsed_values` method
            // is provided by Dioxus and works with any form element that has `name` attributes.
            let values: LoginForm = evt.parsed_values().unwrap();

            // Call the login endpoint
            login(Form(values)).await;
        },
        input { r#type: "text", id: "username", name: "username" }
        label { "Username" }
        input { r#type: "password", id: "password", name: "password" }
        label { "Password" }
        button { "Login" }
    }
}
````

Form elements must have a "name" attribute which will be used during the deserialization process to identify form fields.

Note that `GET` requests will encode the form values in the request URL. This might not work for complex data structures, so it's best practice to use `POST` endpoints for handling form data.

## Multipart

With some forms, you'll need to handle multiple request bodies in a single request. For example, if your form has file inputs, the browser will automatically create a multi-part request with the form values in one body and then file uploads in another.

Dioxus provides the `MultipartFormData` type which will automatically convert `FormEvent` objects into proper multi-part requests.

On the client, you can convert the `FormEvent` with `.into()`:

````
rsx! {
    form {
        display: "flex",
        flex_direction: "column",
        gap: "8px",
        onsubmit: move |evt| async move {
            evt.prevent_default();

            upload(evt.into()).await;
        },
        label { r#for: "headshot", "Photos" }
        input { r#type: "file", name: "headshot", multiple: true, accept: ".png,.jpg,.jpeg" }
        label { r#for: "resume", "Resume" }
        input { r#type: "file", name: "resume", multiple: false, accept: ".pdf" }
        label { r#for: "name", "Name" }
        input { r#type: "text", name: "name", placeholder: "Name" }
        label { r#for: "age", "Age" }
        input { r#type: "number", name: "age", placeholder: "Age" }
        input { r#type: "submit", name: "submit", value: "Submit your resume" }
    }
}
````

On the server, you can use an endpoint that takes `MultipartFormData` and then iterate through the fields using `next_field()`:

````rust
#[post("/api/upload-multipart")]
async fn upload(mut form: MultipartFormData) -> Result<()> {
    while let Ok(Some(field)) = form.next_field().await {
        let name = field.name().unwrap_or("<none>").to_string();
        let file_name = field.file_name().unwrap_or("<none>").to_string();
        let content_type = field.content_type().unwrap_or("<none>").to_string();
        let bytes = field.bytes().await;

        // ...
    }

    Ok(())
}
````

Currently Dioxus does not support typed `MultipartFormData` objects, but it *is* something we'd like to add in the future.
# Authentication

Most production-ready apps have some sort of authentication and authorization to restrict data and resources from being publicly accessible to all users.

Dioxus does *not* provide a built-in way of managing authentication. However, since auth is such a critical component of building fullstack apps, this chapter will help guide you through the process of implementing it for your app.

 > 
 > In the future, we'd like to integrate sessions and auth directly into Dioxus fullstack, but for now, you'll need to rely on 3rd-party libraries.

## What is Authentication?

Authentication is the process of verifying a user's identity, usually through the use of cookies or access tokens.

Your app should not blindly accept actions from untrusted users, so it's important to verify that a user who claims to be "Bob" *actually is* "Bob".

## What is Authorization?

Authorization is the *next step* after authentication. Once a user's identity is verified, you must then verify that they can actually take a given action.

You don't want one user to change another user's login credentials, so any action related to user data must be *authorized* first.

## Auth is Built on Sessions

Fundamentally, auth works by associating a users *connection* with some *session* in a database. As a user traverses our page and makes actions, we need some way of identifying their session on the server.

Usually, this is done via a middleware that automatically registers every connection with a row in your database. If the user is *unauthenticated*, you can either store their session as an anonymous user, or a ignore it completely.

A session is usually inserted with an axum-level middleware:

````rust
dioxus::server::router(app)
    .layer(axum::middleware::from_fn(
        |request: Request, next: Next| async move {
            // Get the auth token and then insert the session into the request's extensions
            //
            // We need to look up the auth token in our database to retrieve the session
            if let Some(token) = request.headers().get("Authorization") {
                if let Some(session) = DATABASE.get_session(token) {
                    request.extensions_mut().insert(session);
                }
            }

            // And then run the request
            next.run(request).await
        },
    ))
````

## Libraries for Authentication

You can implement session lookup and session creation system manually, or use a 3rd-party library like [`axum_session_auth`](https://crates.io/crates/axum_session_auth) to handle most of the complexity for you.

Generally, you'll add a 3rd-party library as a `.layer()` on your router, and it will add the `Session` extension to your requests automatically:

````rust
dioxus::serve(|| async move {
    // Create an axum router that dioxus will attach the app to
    Ok(dioxus::server::router(app)
        // Add the `AuthLayer`
        .layer(
            AuthLayer::new(Some(db.clone()))
                .with_config(AuthConfig::<i64>::default().with_anonymous_user_id(Some(1))),
        )
        // And add the `SessionLayer`
        .layer(SessionLayer::new(
            SessionStore::<SessionSqlitePool>::new(
                Some(db.into()),
                SessionConfig::default().with_table_name("test_table"),
            )
            .await?,
        )))
})
````

The `axum_session_auth` crate integrates with `sqlx` to automatically manage sessions using a row in your database.

## Auth as an Extractor

You can use extractors to integrate auth with your Fullstack application.

You can create a custom extractor to extract the auth session from the request. From that auth session, you can check if the user has the required privileges before returning the private data.

Because the sessions are inserted into every request, you can extract them with server-only extractors:

````rust
/// We use the `auth::Session` extractor to get access to the current user session.
/// This lets us modify the user session, log in/out, and access the current user.
#[post("/api/user/login", auth: auth::Session)]
pub async fn login() -> Result<()> {
    auth.login_user(2);
    Ok(())
}

/// Just like `login`, but this time we log out the user.
#[post("/api/user/logout", auth: auth::Session)]
pub async fn logout() -> Result<()> {
    auth.logout_user();
    Ok(())
}
````

A [full auth example](https://github.com/DioxusLabs/dioxus/blob/7102bc3b6a0ddea3a9e71423fc6d667df8d956f3/examples/07-fullstack/auth/src/main.rs) with the complete implementation is available in the fullstack examples.

## Auth as a 3rd-party service

Implementing auth can be somewhat tedious, so there are a number of 3rd party services that simplify the implementation for you. With these services, the session and auth data tends to not live in *your database*, but rather theirs.

We don't recommend any particular 3rd party service. However, there are some solutions like Supabase and Firebase where sessions are managed in your database, but with prebuilt infrastructure for you to integrate with.
# Native Clients

So far, we've focused on using fullstack alongside a web application. However, not all apps you'll build with Dioxus will be loaded in a web browser. Dioxus supports mobile apps and desktop apps as well.

On these platforms, fullstack works a bit differently. You can still use server functions, but things like server-side-rendering no-longer apply.

## Developing a Native Fullstack App

Developing a native fullstack app works just the same as developing a fullstack web app. Make sure your `Cargo.toml` has the appropriate features:

````toml
[dependencies]
dioxus = { version = "0.7", features = ["fullstack"] }

[features]
server = ["dioxus/server"]
desktop = ["dioxus/desktop"]
````

And then, to serve the app, use `dx serve --<platform>`:

````sh
dx serve --desktop
````

## Server Functions for Native App

When you build a native app that relies on server functions, you can freely call any server function just as you would with a web app.

This simple hello world app works the same on web, desktop, and mobile:

````rust
use dioxus::prelude::*;

fn main() {
    dioxus::launch(|| {
        let mut message = use_action(get_message);

        rsx! {
            h1 { "Server says: "}
            pre { "{message:?}"}
            button { onclick: move |_| message.call("world".into(), 30), "Click me!" }
        }
    });
}

#[get("/api/{name}/?age")]
async fn get_message(name: String, age: i32) -> Result<String> {
    Ok(format!("Hello {}, you are {} years old!", name, age))
}
````

Your native code can still make requests to your backend. However, when if you deployed your app to production, you might notice that the native app *does not know where to make requests*.

In the web, requests are always made to the current host origin. For example, requests to this endpoint are made to `/api/dogs`:

````rust
#[get("/api/dogs")]
async fn get_message() -> Result<()> {
    // ..
}
````

Desktop and mobiles are not served from a specific URL, and thus do not know which host to make a request to.

To set a specific server URL, you must call `set_server_url` before making any requests:

````rust
fn main() {
    #[cfg(not(feature = "server"))]
    dioxus::fullstack::set_server_url("https://hot-dog.fly.dev");

    dioxus::launch(app);
}
````

This ensures that requests are always properly joined with the correct host.

## Disabled Fullstack Features

When using fullstack with native apps, a number of features and optimizations are disabled. Native apps are usually meant to be used offline, so their rendering needs to happen entirely on the client. Architecturally, native apps are similar to single-page-applications (SPA) where the bundle loads and *then* HTTP requests are made to load content.

As such, a number of features are disabled:

* There is no hydration context, and thus no hydration data to hydrate the page
* The app is never rendered on the server, skipping `#[cfg(feature = "server")]` code
* There is no `FullstackContext` when rendering components
* HTML Streaming and SSG have no effect

Functionally, this won't change how you build your apps, but you should be aware that some code might never be executed.

## Prefer Known Endpoints

Dioxus supports two ways of annotating server functions:

* Explicitly with `#[get]`, `#[post]`, `#[delete]`, etc.
* Anonymously with `#[server]`

When you use the `#[server]` macro, the endpoint path is free to change as you update the endpoint's signature and body. If you re-redeploy your backend, URLs that worked previously are not guaranteed to exist in the future.

````rust
// ❌ this endpoint generates `/api/do_it12nldkj2378jnakls`
#[server]
async fn do_it() -> Result<()> {
    //
}
````

Because the endpoint receives a hash, its name is unique and might change as you update its code.

When using server functions with native clients, we strongly recommend using the `#[get]` / `#[post]` annotations since they guarantee a stable endpoint.

````rust
// ✅ This endpoint is stable
#[post("/api/do_it")]
async fn do_it() -> Result<()> {
    //
}
````

## Versioning

Because native clients are distributed as downloadable software, they might not always up to date as the latest version of your code. This can be particularly challenging when you want to update the signature of an endpoint.

````rust
// version 1
#[post("/api/do_it")]
async fn do_it() -> Result<()> { /* */ }

// version 2
// ❌ we are breaking old clients!
#[post("/api/do_it")]
async fn do_it(name: String) -> Result<()>  { /* */ }
````

We hope this problem is obvious to you - if you re-redploy your backend with breaking changes, previous clients will break!

To upgrade APIs, we recommend one of two options:

* Use `Option<T>` to add new fields
* Use `/api/v1`, `/api/v2/` versioning

For most API upgrades, you can simply add new fields by making new values optional with `Option<T>`:

````rust
// version 2
// ✅ Option<String> means `name` is not required
#[post("/api/do_it")]
async fn do_it(name: Option<String>) -> Result<()>  { /* */ }
````

For API changes that require much larger changes, we recommend using a versioning scheme to create different versions of the API accessible by the client:

````rust
// This is at /api/v1/
#[post("/api/v1/do_it")]
async fn do_it() -> Result<()> { /* */ }

// This is at api/v2
#[post("/api/v2/do_it")]
async fn do_it(name: String) -> Result<()> { /* */ }
````

Creating different API versions is common practice and helps prevent breaking old clients as you update your app.

## Deploying

You can deploy native fullstack apps just the same as you would deploy a regular web app. Server apps always generate a `server` binary and a `/public/` folder. Native apps will generate an app bundle (`.app`, `.ipa`, `.apk`, etc).

You can distribute the native app via an app store or by making the file downloadable to your users.

To distribute the server, simply upload it to a hosting provider of your choice. As long as you set the `server_url` in the native app, you should be able to access your backend from the native client.
# Streaming

For some sites, it is extremely important to optimize "time-to-first-byte". Users want to see results as soon as possible, even if not *all* results are ready immediately.

Dioxus supports this usecase with a technology called *"HTML Streaming"*. HTML streaming allows you to quickly send an initial skeleton of the page to the user and then fill in various components as their data loads.

## What is Streaming?

The default rendering mode in dioxus fullstack waits for all [suspense boundaries](../basics/suspense.md#suspense-with-fullstack) to resolve before sending the entire page as HTML to the client. If you have a page with multiple chunks of async data, the server will wait for all of them to complete before rendering the page.

When streaming is enabled, the server can send chunks of HTML to the client as soon as each suspense boundary resolves. You can start interacting with a page as soon as the first part of the HTML is sent, instead of waiting for the entire page to be ready. This can lead to a much faster initial load time.

Bellow is the same [hackernews example](https://github.com/DioxusLabs/dioxus/tree/main/examples/01-app-demos/hackernews) rendered with and without streaming enabled. While both pages take the same amount of time to load all the data, the page with streaming enabled on the left shows you the data as soon as it becomes available.

````inject-dioxus
DemoFrame {
    overflow: "hidden",
    FakePage {
        div {
            display: "flex",
            flex_direction: "row",
            justify_content: "space-around",
            align_items: "center",
            height: "100%",
            width: "100%",
            img {
                max_height: "100%",
                max_width: "50%",
                aria_label: "Hackernews with streaming enabled",
                src: asset!("/assets/static/streaming-enabled-hackernews"),
            }
            img {
                max_height: "100%",
                max_width: "50%",
                aria_label: "Hackernews with streaming disabled",
                src: asset!("/assets/static/streaming-disabled-hackernews"),
            }
        }
    }
}
````

## SEO and No JS

When streaming is enabled, all of the contents of the page are still rendered into the html document, so search engines can still crawl and index the full content of the page. However, the content will not be visible to users unless they have JavaScript enabled. If you want to support users without JavaScript, you will need to disable streaming and use the default rendering mode.

## Do You Need Streaming?

HTML streaming is best suited for apps like e-commerce sites where much of the data is quick to render (the product image, description, etc) but some data takes much longer to resolve. In these cases, you don't want to make the user wait too long for the page to load, so you send down what you have as soon as possible.

Streaming adds some slight overhead and complexity to your app, so it's disabled by default.

## Enabling Streaming

You can enable streaming in the ServeConfig builder with the `enable_out_of_order_streaming` method. If you are launching your application through the `dioxus::LaunchBuilder`, you can use the `with_cfg` method to pass in a configuration that enables streaming:

````rs@streaming.rs
pub fn main() {
    dioxus::LaunchBuilder::new()
        .with_cfg(server_only! {
            dioxus::server::ServeConfig::builder().enable_out_of_order_streaming()
        })
        .launch(app);
}
````

or if you are using a custom axum server, you can pass the config into `serve_dioxus_application` directly:

````rs@streaming.rs
#[cfg(feature = "server")]
#[tokio::main]
async fn main() {
    let addr = dioxus::cli_config::fullstack_address_or_localhost();
    let router = axum::Router::new()
        // Server side render the application, serve static assets, and register server functions
        .serve_dioxus_application(
            dioxus::server::ServeConfig::builder().enable_out_of_order_streaming(),
            app,
        )
        .into_make_service();
    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, router).await.unwrap();
}
````

## Head elements with streaming

Head elements can only be rendered in the initial HTML chunk that contains the `<head>` tag. You should include all of your `document::Link`, `document::Meta`, and `document::Title` elements in the first part of your page if possible. If you have any head elements that are not included in the first chunk, they will be rendered by the client after hydration instead, which will not be visible to any search engines or users without JavaScript enabled.

The initial chunk of HTML is send after [commit_initial_chunk](https://docs.rs/dioxus-fullstack/0.7.0-alpha.1/dioxus_fullstack/prelude/fn.commit_initial_chunk.html) is called for the first time. If you are using the router, this will happen automatically when all suspense boundaries above the router are resolved. If you are not using the router, you can call `commit_initial_chunk` manually after all of your blocking head elements have been rendered.

````rs@streaming.rs
/// An enum of all of the possible routes in the app.
#[derive(Routable, Clone)]
enum Route {
    // The home page is at the / route
    #[route("/")]
    Home,
}

fn Home() -> Element {
    let title = use_server_future(get_title)?;
    let description = use_server_future(get_description)?;

    rsx! {
        // This will be rendered on the server because it is inside the same (root)
        // suspense boundary as the `Router` component.
        document::Title { {title} }
        SuspenseBoundary {
            fallback: |_| {
                rsx! { "Loading..." }
            },
            AsyncHead {}
        }
    }
}

fn AsyncHead() -> Element {
    let description = use_server_future(get_description)?;
    // The resource should always be resolved at this point because the `?` above bubbles
    // up the async case if it is pending
    let current_description = description.read_unchecked();
    let current_description = current_description.as_ref().unwrap();

    rsx! {
        // This will be rendered on the client because it is in a
        // suspense boundary below the `Router` component.
        document::Meta { name: "description", content: "{current_description}" }
    }
}
````

## Response Headers with Streaming

When rendering an app with streaming enabled, Dioxus will wait for the app to commit its initial skeleton before sending a response to the user's request. This is done with the `commit_initial_chunk()` method.

Once the initial chunk is committed, you can no longer change the headers of the response nor change the HTTP status.

For example, you might have a server function that throws a 404 status code:

````rust
#[get("/api/post/{id}")]
async fn get_post(id: u32) -> Result<String, HttpError> {
    match id {
        1 => Ok("first post".to_string()),
        _ => HttpError::not_found("Post not found")?,
    }
}
````

With streaming disabled, if this status code is bubbled to the root component as an error, the user will get a `404 NOT FOUND` status in the response.

````rust
#[component]
fn Post(id: ReadSignal<u32>) -> Element {
    // If `get_post` returns a 404, then the user will also get a 404
    let post_data = use_loader(move || get_post(id()))?;

    rsx! {
        h1 { "Post {id}" }
        p { "{post_data}" }
    }
}
````

However, when streaming is *enabled*, the status code from this server function will only be propagated to the user *before* the call to `commit_initial_chunk()`.

Normally, you won't call `commit_initial_chunk()` yourself since the `Router` component calls it for you once the root suspense boundary is resolved.

This means that, when suspense is enabled, server functions won't set the HTTP status code if they are called from within a dedicated suspense boundary:

````rust
fn Home() -> Element {
    rsx! {
        SuspenseBoundary {
            fallback: |_| rsx! { "loading..." },

            // Errors here won't propagate to the response headers
            Post { id: 123 }
        }
    }
}
````
# Static Site Generation

Static site generation (SSG) lets you pre-generate all static pages of your application at build time. Once you have the static HTML pages, you can deploy them to any static hosting provider like GitHub Pages.

SSG is extremely powerful since it lets you cache the rendering of your pages before deploying to production. This cuts down on bandwidth costs, lets you cache content on a CDN, and allows for deploying *without* a server. Many deploy providers let you deploy SSG sites for free!

## How Dioxus SSG works

Dioxus SSG works by running your app locally, querying the app for a sitemap, and then indexing your site using `curl` requests manually. If your site is configured to use SSG, then it will cache HTML for each page on the filesystem.

This approach to SSG is quite different than a traditional static-site-generator like Hugo, Jekyll, or Zola. Dioxus SSG is designed to let you write your entire site in Rust, load data however you want, and then deploy a hybrid SSG app that loads SPA content.

## You might not need SSG

Even if your app has a significant amount of static content, you might not actually need SSG. You should use SSG in a few cases:

* You have *lots* of static content that benefits from pre-rendering before deploy
* You don't need a backend for your site

Sites like docs and portfolios benefit from SSG while apps like photo editors will not. In many cases, you can simply set `Cache-Control` headers while rendering pages and let your CDN or reverse-proxy handle caching for you!

## Setting up the ServeConfig

SSG builds on top of the incremental rendering feature of Dioxus fullstack. We need to set up the `ServeConfig` to enable incremental rendering. The incremental config needs to render to the `public` directory where Dioxus places all other public files like the wasm binary and static assets. The `public` directory in the web folder will always be placed alongside the server binary.

````rs@static_site_generation.rs
fn main() {
    dioxus::LaunchBuilder::new()
        // Set the server config only if we are building the server target
        .with_cfg(server_only! {
            ServeConfig::builder()
                // Enable incremental rendering
                .incremental(
                    dioxus::server::IncrementalRendererConfig::new()
                        // Store static files in the public directory where other static assets like wasm are stored
                        .static_dir(
                            std::env::current_exe()
                                .unwrap()
                                .parent()
                                .unwrap()
                                .join("public")
                        )
                        // Don't clear the public folder on every build. The public folder has other files including the wasm
                        // binary and static assets required for the app to run
                        .clear_cache(false)
                )
                .enable_out_of_order_streaming()
        })
        .launch(app);
}
````

## Configuring static routes

Once you have incremental rendering enabled, you need to tell the CLI about the static routes in your app. The CLI looks for a server function at the endpoint `"static_routes"` that returns a list of all static urls. It will call this server function at build time and pre-render all of the routes in the list.

````rs@static_site_generation.rs
#[derive(Routable, Clone, PartialEq)]
pub enum Route {
    // Any routes with no dynamic segments in your router will be included in the static routes list
    #[route("/")]
    Index {},

    #[route("/other")]
    Other {},
}

// The server function at the endpoint "static_routes" will be called by the CLI to generate the list of static
// routes. You must explicitly set the endpoint to `"static_routes"` in the server function attribute instead of
// the default randomly generated endpoint.
#[server(endpoint = "static_routes", output = server_fn::codec::Json)]
async fn static_routes() -> Result<Vec<String>, ServerFnError> {
    // The `Routable` trait has a `static_routes` method that returns all static routes in the enum
    Ok(Route::static_routes()
        .iter()
        .map(ToString::to_string)
        .collect())
}
````

## Publishing static sites

Finally, you can bundle your site with `dx bundle --web --ssg`. Once the CLI finishes bundling, you should see a `public` folder in the dx folder of your project:

![Dioxus SSG](/assets/06_docs/ssg_folder.png)

The folder contains all of the static assets that you need to serve your site. You can copy the public folder into any static hosting provider like GitHub Pages.
